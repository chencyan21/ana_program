{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from IPython.display import display,HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Deep Dive: RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_text_files(path, folders = ['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#100000) [Path('C:/Users/C1602/.fastai/data/imdb/test/neg/0_2.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10000_4.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10001_1.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10002_3.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10003_3.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10004_2.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10005_2.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10006_2.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10007_4.txt'),Path('C:/Users/C1602/.fastai/data/imdb/test/neg/10008_4.txt')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once again Mr. Costner has dragged out a movie for far longer than necessar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read(); txt[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#187) ['Once','again','Mr.','Costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','Aside','from','the','terrific','sea','rescue','sequences',',','of','which','there','are','very','few','I'...]\n"
     ]
    }
   ],
   "source": [
    "spacy = WordTokenizer()\n",
    "toks = first(spacy([txt]))\n",
    "print(coll_repr(toks, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(spacy(['The U.S. dollar $1 is $1.00.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object SpacyTokenizer.__call__.<locals>.<genexpr> at 0x000001DBB3D2FD80>\n"
     ]
    }
   ],
   "source": [
    "print(spacy(['The U.S. dollar $1 is $1.00.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','xxmaj','aside','from','the','terrific','sea','rescue','sequences',',','of','which'...]\n"
     ]
    }
   ],
   "source": [
    "tkn = Tokenizer(spacy)\n",
    "print(coll_repr(tkn(txt), 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#13) ['xxbos','xxmaj','the','xxup','u.s','.','dollar','$','1','is','$','1.00','.']\n"
     ]
    }
   ],
   "source": [
    "print(coll_repr(tkn('The U.S. dollar $1 is $1.00.'), 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function fastai.text.core.fix_html(x)>,\n",
       " <function fastai.text.core.replace_rep(t)>,\n",
       " <function fastai.text.core.replace_wrep(t)>,\n",
       " <function fastai.text.core.spec_add_spaces(t)>,\n",
       " <function fastai.text.core.rm_useless_spaces(t)>,\n",
       " <function fastai.text.core.replace_all_caps(t)>,\n",
       " <function fastai.text.core.replace_maj(t)>,\n",
       " <function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults.text_proc_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = L(o.open().read() for o in files[:2000])\n",
    "# L: Behaves like a list of items but can also index with list of indices or masks\n",
    "# 可以视作数组，有index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword(sz):\n",
    "    sp = SubwordTokenizer(vocab_sz=sz)\n",
    "    sp.setup(txts)\n",
    "    return ' '.join(first(sp([txt]))[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁O n ce ▁again ▁M r . ▁Co st n er ▁has ▁ d ra g g ed ▁out ▁a ▁movie ▁for ▁far ▁long er ▁than ▁ ne ce s s ar y . ▁A side ▁from ▁the ▁ ter'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁ O n ce ▁a g a in ▁ M r . ▁ C o s t n er ▁ h a s ▁ d ra g g ed ▁ o u t ▁a ▁movie ▁for ▁f ar ▁ l'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁On ce ▁again ▁Mr . ▁Costner ▁has ▁dragged ▁out ▁a ▁movie ▁for ▁far ▁longer ▁than ▁necessary . ▁A side ▁from ▁the ▁terrific ▁sea ▁rescue ▁sequences , ▁of ▁which ▁there ▁are ▁very ▁few ▁I ▁just ▁did ▁not ▁care ▁about ▁any ▁of'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','xxmaj','aside','from','the','terrific','sea','rescue','sequences',',','of','which'...]\n"
     ]
    }
   ],
   "source": [
    "toks = tkn(txt)\n",
    "print(coll_repr(tkn(txt), 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对txt中前200个文件进行处理，使用tkn这个tokenizer对所有的文件进行tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has'...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200 = txts[:200].map(tkn)\n",
    "toks200[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#200) [['xxbos', 'xxmaj', 'once', 'again', 'xxmaj', 'mr', '.', 'xxmaj', 'costner', 'has', 'dragged', 'out', 'a', 'movie', 'for', 'far', 'longer', 'than', 'necessary', '.', 'xxmaj', 'aside', 'from', 'the', 'terrific', 'sea', 'rescue', 'sequences', ',', 'of', 'which', 'there', 'are', 'very', 'few', 'i', 'just', 'did', 'not', 'care', 'about', 'any', 'of', 'the', 'characters', '.', 'xxmaj', 'most', 'of', 'us', 'have', 'ghosts', 'in', 'the', 'closet', ',', 'and', 'xxmaj', 'costner', \"'s\", 'character', 'are', 'realized', 'early', 'on', ',', 'and', 'then', 'forgotten', 'until', 'much', 'later', ',', 'by', 'which', 'time', 'i', 'did', 'not', 'care', '.', 'xxmaj', 'the', 'character', 'we', 'should', 'really', 'care', 'about', 'is', 'a', 'very', 'cocky', ',', 'overconfident', 'xxmaj', 'ashton', 'xxmaj', 'kutcher', '.', 'xxmaj', 'the', 'problem', 'is', 'he', 'comes', 'off', 'as', 'kid', 'who', 'thinks', 'he', \"'s\", 'better', 'than', 'anyone', 'else', 'around', 'him', 'and', 'shows', 'no', 'signs', 'of', 'a', 'cluttered', 'closet', '.', 'xxmaj', 'his', 'only', 'obstacle', 'appears', 'to', 'be', 'winning', 'over', 'xxmaj', 'costner', '.', 'xxmaj', 'finally', 'when', 'we', 'are', 'well', 'past', 'the', 'half', 'way', 'point', 'of', 'this', 'stinker', ',', 'xxmaj', 'costner', 'tells', 'us', 'all', 'about', 'xxmaj', 'kutcher', \"'s\", 'ghosts', '.', 'xxmaj', 'we', 'are', 'told', 'why', 'xxmaj', 'kutcher', 'is', 'driven', 'to', 'be', 'the', 'best', 'with', 'no', 'prior', 'inkling', 'or', 'foreshadowing', '.', 'xxmaj', 'no', 'magic', 'here', ',', 'it', 'was', 'all', 'i', 'could', 'do', 'to', 'keep', 'from', 'turning', 'it', 'off', 'an', 'hour', 'in', '.'],['xxbos', 'xxmaj', 'this', 'is', 'an', 'example', 'of', 'why', 'the', 'majority', 'of', 'action', 'films', 'are', 'the', 'same', '.', 'xxmaj', 'generic', 'and', 'boring', ',', 'there', \"'s\", 'really', 'nothing', 'worth', 'watching', 'here', '.', 'a', 'complete', 'waste', 'of', 'the', 'then', 'barely', '-', 'tapped', 'talents', 'of', 'ice', '-', 't', 'and', 'xxmaj', 'ice', 'xxmaj', 'cube', ',', 'who', \"'ve\", 'each', 'proven', 'many', 'times', 'over', 'that', 'they', 'are', 'capable', 'of', 'acting', ',', 'and', 'acting', 'well', '.', 'xxmaj', 'do', \"n't\", 'bother', 'with', 'this', 'one', ',', 'go', 'see', 'xxmaj', 'new', 'xxmaj', 'jack', 'xxmaj', 'city', ',', 'xxmaj', 'ricochet', 'or', 'watch', 'xxmaj', 'new', 'xxmaj', 'york', 'xxmaj', 'undercover', 'for', 'ice', '-', 't', ',', 'or', 'xxmaj', 'boyz', 'n', 'the', 'xxmaj', 'hood', ',', 'xxmaj', 'higher', 'xxmaj', 'learning', 'or', 'xxmaj', 'friday', 'for', 'xxmaj', 'ice', 'xxmaj', 'cube', 'and', 'see', 'the', 'real', 'deal', '.', 'ice', '-', 't', \"'s\", 'horribly', 'cliched', 'dialogue', 'alone', 'makes', 'this', 'film', 'grate', 'at', 'the', 'teeth', ',', 'and', 'xxmaj', 'i', \"'m\", 'still', 'wondering', 'what', 'the', 'heck', 'xxmaj', 'bill', 'xxmaj', 'paxton', 'was', 'doing', 'in', 'this', 'film', '?', 'xxmaj', 'and', 'why', 'the', 'heck', 'does', 'he', 'always', 'play', 'the', 'exact', 'same', 'character', '?', 'xxmaj', 'from', 'xxmaj', 'aliens', 'onward', ',', 'every', 'film', 'xxmaj', 'i', \"'ve\", 'seen', 'with', 'xxmaj', 'bill', 'xxmaj', 'paxton', 'has', 'him', 'playing', 'the', 'exact', 'same', 'irritating', 'character', ',', 'and', 'at', 'least', 'in', 'xxmaj', 'aliens', 'his', 'character', 'died', ',', 'which', 'made', 'it', 'somewhat', 'gratifying', '…', '\\n\\n', 'xxmaj', 'overall', ',', 'this', 'is', 'second', '-', 'rate', 'action', 'trash', '.', 'xxmaj', 'there', 'are', 'countless', 'better', 'films', 'to', 'see', ',', 'and', 'if', 'you', 'really', 'want', 'to', 'see', 'this', 'one', ',', 'watch', 'xxmaj', 'judgement', 'xxmaj', 'night', ',', 'which', 'is', 'practically', 'a', 'carbon', 'copy', 'but', 'has', 'better', 'acting', 'and', 'a', 'better', 'script', '.', 'xxmaj', 'the', 'only', 'thing', 'that', 'made', 'this', 'at', 'all', 'worth', 'watching', 'was', 'a', 'decent', 'hand', 'on', 'the', 'camera', '-', 'the', 'cinematography', 'was', 'almost', 'refreshing', ',', 'which', 'comes', 'close', 'to', 'making', 'up', 'for', 'the', 'horrible', 'film', 'itself', '-', 'but', 'not', 'quite', '.', '4', '/', '10', '.'],['xxbos', 'xxmaj', 'first', 'of', 'all', 'i', 'hate', 'those', 'moronic', 'rappers', ',', 'who', \"could'nt\", 'act', 'if', 'they', 'had', 'a', 'gun', 'pressed', 'against', 'their', 'foreheads', '.', 'xxmaj', 'all', 'they', 'do', 'is', 'curse', 'and', 'shoot', 'each', 'other', 'and', 'acting', 'like', \"cliché'e\", 'version', 'of', 'gangsters', '.', '\\n\\n', 'xxmaj', 'the', 'movie', 'does', \"n't\", 'take', 'more', 'than', 'five', 'minutes', 'to', 'explain', 'what', 'is', 'going', 'on', 'before', 'we', \"'re\", 'already', 'at', 'the', 'warehouse', 'xxmaj', 'there', 'is', 'not', 'a', 'single', 'sympathetic', 'character', 'in', 'this', 'movie', ',', 'except', 'for', 'the', 'homeless', 'guy', ',', 'who', 'is', 'also', 'the', 'only', 'one', 'with', 'half', 'a', 'brain', '.', '\\n\\n', 'xxmaj', 'bill', 'xxmaj', 'paxton', 'and', 'xxmaj', 'william', 'xxmaj', 'sadler', 'are', 'both', 'hill', 'billies', 'and', 'xxmaj', 'sadlers', 'character', 'is', 'just', 'as', 'much', 'a', 'villain', 'as', 'the', 'gangsters', '.', 'i', \"did'nt\", 'like', 'him', 'right', 'from', 'the', 'start', '.', '\\n\\n', 'xxmaj', 'the', 'movie', 'is', 'filled', 'with', 'pointless', 'violence', 'and', 'xxmaj', 'walter', 'xxmaj', 'hills', 'specialty', ':', 'people', 'falling', 'through', 'windows', 'with', 'glass', 'flying', 'everywhere', '.', 'xxmaj', 'there', 'is', 'pretty', 'much', 'no', 'plot', 'and', 'it', 'is', 'a', 'big', 'problem', 'when', 'you', 'root', 'for', 'no', '-', 'one', '.', 'xxmaj', 'everybody', 'dies', ',', 'except', 'from', 'xxmaj', 'paxton', 'and', 'the', 'homeless', 'guy', 'and', 'everybody', 'get', 'what', 'they', 'deserve', '.', '\\n\\n', 'xxmaj', 'the', 'only', 'two', 'black', 'people', 'that', 'can', 'act', 'is', 'the', 'homeless', 'guy', 'and', 'the', 'junkie', 'but', 'they', \"'re\", 'actors', 'by', 'profession', ',', 'not', 'annoying', 'ugly', 'brain', 'dead', 'rappers', '.', '\\n\\n', 'xxmaj', 'stay', 'away', 'from', 'this', 'crap', 'and', 'watch', '48', 'hours', '1', 'and', '2', 'instead', '.', 'xxmaj', 'at', 'lest', 'they', 'have', 'characters', 'you', 'care', 'about', ',', 'a', 'sense', 'of', 'humor', 'and', 'nothing', 'but', 'real', 'actors', 'in', 'the', 'cast', '.'],['xxbos', 'xxmaj', 'not', 'even', 'the', 'xxmaj', 'beatles', 'could', 'write', 'songs', 'everyone', 'liked', ',', 'and', 'although', 'xxmaj', 'walter', 'xxmaj', 'hill', 'is', 'no', 'mop', '-', 'top', 'he', \"'s\", 'second', 'to', 'none', 'when', 'it', 'comes', 'to', 'thought', 'provoking', 'action', 'movies', '.', 'xxmaj', 'the', 'nineties', 'came', 'and', 'social', 'platforms', 'were', 'changing', 'in', 'music', 'and', 'film', ',', 'the', 'emergence', 'of', 'the', 'xxmaj', 'rapper', 'turned', 'movie', 'star', 'was', 'in', 'full', 'swing', ',', 'the', 'acting', 'took', 'a', 'back', 'seat', 'to', 'each', 'man', \"'s\", 'overpowering', 'regional', 'accent', 'and', 'transparent', 'acting', '.', 'xxmaj', 'this', 'was', 'one', 'of', 'the', 'many', 'ice', '-', 't', 'movies', 'i', 'saw', 'as', 'a', 'kid', 'and', 'loved', ',', 'only', 'to', 'watch', 'them', 'later', 'and', 'cringe', '.', 'xxmaj', 'bill', 'xxmaj', 'paxton', 'and', 'xxmaj', 'william', 'xxmaj', 'sadler', 'are', 'firemen', 'with', 'basic', 'lives', 'until', 'a', 'burning', 'building', 'tenant', 'about', 'to', 'go', 'up', 'in', 'flames', 'hands', 'over', 'a', 'map', 'with', 'gold', 'implications', '.', 'i', 'hand', 'it', 'to', 'xxmaj', 'walter', 'for', 'quickly', 'and', 'neatly', 'setting', 'up', 'the', 'main', 'characters', 'and', 'location', '.', 'xxmaj', 'but', 'i', 'fault', 'everyone', 'involved', 'for', 'turning', 'out', 'xxmaj', 'lame', '-', 'o', 'performances', '.', 'xxmaj', 'ice', '-', 't', 'and', 'cube', 'must', 'have', 'been', 'red', 'hot', 'at', 'this', 'time', ',', 'and', 'while', 'xxmaj', 'i', \"'ve\", 'enjoyed', 'both', 'their', 'careers', 'as', 'rappers', ',', 'in', 'my', 'opinion', 'they', 'fell', 'flat', 'in', 'this', 'movie', '.', 'xxmaj', 'it', \"'s\", 'about', 'ninety', 'minutes', 'of', 'one', 'guy', 'ridiculously', 'turning', 'his', 'back', 'on', 'the', 'other', 'guy', 'to', 'the', 'point', 'you', 'find', 'yourself', 'locked', 'in', 'multiple', 'states', 'of', 'disbelief', '.', 'xxmaj', 'now', 'this', 'is', 'a', 'movie', ',', 'its', 'not', 'a', 'documentary', 'so', 'i', 'wo', 'nt', 'waste', 'my', 'time', 'recounting', 'all', 'the', 'stupid', 'plot', 'twists', 'in', 'this', 'movie', ',', 'but', 'there', 'were', 'many', ',', 'and', 'they', 'led', 'nowhere', '.', 'i', 'got', 'the', 'feeling', 'watching', 'this', 'that', 'everyone', 'on', 'set', 'was', 'sord', 'of', 'confused', 'and', 'just', 'playing', 'things', 'off', 'the', 'cuff', '.', 'xxmaj', 'there', 'are', 'two', 'things', 'i', 'still', 'enjoy', 'about', 'it', ',', 'one', 'involves', 'a', 'scene', 'with', 'a', 'needle', 'and', 'the', 'other', 'is', 'xxmaj', 'sadler', \"'s\", 'huge', '45', 'pistol', '.', 'xxmaj', 'bottom', 'line', 'this', 'movie', 'is', 'like', 'domino', \"'s\", 'pizza', '.', 'xxmaj', 'yeah', 'ill', 'eat', 'it', 'if', 'xxmaj', 'i', \"'m\", 'hungry', 'and', 'i', 'do', \"n't\", 'feel', 'like', 'cooking', ',', 'xxmaj', 'but', 'xxmaj', 'i', \"'m\", 'well', 'aware', 'it', 'tastes', 'like', 'crap', '.', '3', 'stars', ',', 'meh', '.'],['xxbos', 'xxmaj', 'brass', 'pictures', '(', 'movies', 'is', 'not', 'a', 'fitting', 'word', 'for', 'them', ')', 'really', 'are', 'somewhat', 'brassy', '.', 'xxmaj', 'their', 'alluring', 'visual', 'qualities', 'are', 'reminiscent', 'of', 'expensive', 'high', 'class', 'xxup', 'tv', 'commercials', '.', 'xxmaj', 'but', 'unfortunately', 'xxmaj', 'brass', 'pictures', 'are', 'feature', 'films', 'with', 'the', 'pretense', 'of', 'wanting', 'to', 'entertain', 'viewers', 'for', 'over', 'two', 'hours', '!', 'xxmaj', 'in', 'this', 'they', 'fail', 'miserably', ',', 'their', 'undeniable', ',', 'but', 'rather', 'soft', 'and', 'flabby', 'than', 'steamy', ',', 'erotic', 'qualities', 'non', 'withstanding', '.', '\\n\\n', 'xxmaj', 'senso', \"'\", '45', 'is', 'a', 'remake', 'of', 'a', 'film', 'by', 'xxmaj', 'luchino', 'xxmaj', 'visconti', 'with', 'the', 'same', 'title', 'and', 'xxmaj', 'alida', 'xxmaj', 'valli', 'and', 'xxmaj', 'farley', 'xxmaj', 'granger', 'in', 'the', 'lead', '.', 'xxmaj', 'the', 'original', 'tells', 'a', 'story', 'of', 'senseless', 'love', 'and', 'lust', 'in', 'and', 'around', 'xxmaj', 'venice', 'during', 'the', 'xxmaj', 'italian', 'wars', 'of', 'independence', '.', 'xxmaj', 'brass', 'moved', 'the', 'action', 'from', 'the', '19th', 'into', 'the', '20th', 'century', ',', '1945', 'to', 'be', 'exact', ',', 'so', 'there', 'are', 'xxmaj', 'mussolini', 'murals', ',', 'men', 'in', 'black', 'shirts', ',', 'xxmaj', 'german', 'uniforms', 'or', 'the', 'tattered', 'garb', 'of', 'the', 'partisans', '.', 'xxmaj', 'but', 'it', 'is', 'just', 'window', 'dressing', ',', 'the', 'historic', 'context', 'is', 'completely', 'negligible', '.', '\\n\\n', 'xxmaj', 'anna', 'xxmaj', 'galiena', 'plays', 'the', 'attractive', 'aristocratic', 'woman', 'who', 'falls', 'for', 'the', 'amoral', 'xxup', 'ss', 'guy', 'who', 'always', 'puts', 'on', 'too', 'much', 'lipstick', '.', 'xxmaj', 'she', 'is', 'an', 'attractive', ',', 'versatile', ',', 'well', 'trained', 'xxmaj', 'italian', 'actress', 'and', 'clearly', 'above', 'the', 'material', '.', 'xxmaj', 'her', 'wide', 'range', 'of', 'facial', 'expressions', '(', 'signalling', 'boredom', ',', 'loathing', ',', 'delight', ',', 'fear', ',', 'hate', '…', 'and', 'ecstasy', ')', 'are', 'the', 'best', 'reason', 'to', 'watch', 'this', 'picture', 'and', 'worth', 'two', 'stars', '.', 'xxmaj', 'she', 'endures', 'this', 'basically', 'trashy', 'stuff', 'with', 'an', 'astonishing', 'amount', 'of', 'dignity', '.', 'i', 'wish', 'some', 'really', 'good', 'parts', 'come', 'along', 'for', 'her', '.', 'xxmaj', 'she', 'really', 'deserves', 'it', '.'],['xxbos', 'a', 'funny', 'thing', 'happened', 'to', 'me', 'while', 'watching', '\"', 'mosquito', '\"', ':', 'on', 'the', 'one', 'hand', ',', 'the', 'hero', 'is', 'a', 'deaf', '-', 'mute', 'and', 'the', 'director', 'is', 'totally', 'unable', 'to', 'make', 'us', 'understand', 'why', 'he', 'does', 'what', 'he', 'does', '(', 'mutilating', 'mannequins', '…', 'er', ',', 'excuse', 'me', ',', 'corpses', ')', 'through', 'his', 'images', '.', 'xxmaj', 'on', 'the', 'other', 'hand', ',', 'the', 'xxmaj', 'english', 'version', 'at', 'least', 'is', 'very', 'badly', 'dubbed', '.', 'xxmaj', 'so', 'i', 'found', 'myself', 'wishing', 'there', 'had', 'been', 'both', 'more', 'xxup', 'and', 'less', 'dialogue', 'at', 'the', 'same', 'time', '!', 'xxmaj', 'this', 'film', 'is', 'stupid', '(', 'funny', 'how', 'this', 'guy', 'has', 'access', 'to', 'every', 'graveyard', 'and', 'mortuary', 'in', 'his', 'town', ')', 'and', 'lurid', '(', 'where', 'would', 'we', 'be', 'in', 'a', '70s', 'exploitationer', 'without', 'our', 'gratuitous', 'lesbian', 'scene', '?', ')', '.', 'xxmaj', 'not', 'to', 'mention', 'the', '\"', 'romantic', '\"', 'aspect', '(', 'oh', ',', 'how', 'sweet', '!', ')', '…', 'miss', 'it', '.', '(', '*', ')'],['xxbos', 'xxmaj', 'this', 'xxmaj', 'german', 'horror', 'film', 'has', 'to', 'be', 'one', 'of', 'the', 'weirdest', 'i', 'have', 'seen', '.', '\\n\\n', 'i', 'was', 'not', 'aware', 'of', 'any', 'connection', 'between', 'child', 'abuse', 'and', 'vampirism', ',', 'but', 'this', 'is', 'supposed', 'based', 'upon', 'a', 'true', 'character', '.', '\\n\\n', 'xxmaj', 'our', 'hero', 'is', 'deaf', 'and', 'mute', 'as', 'a', 'result', 'of', 'repeated', 'beatings', 'at', 'the', 'hands', 'of', 'his', 'father', '.', 'he', 'also', 'has', 'a', 'doll', 'fetish', ',', 'but', 'i', 'can', 'not', 'figure', 'out', 'where', 'that', 'came', 'from', '.', 'xxmaj', 'his', 'co', '-', 'workers', 'find', 'out', 'and', 'tease', 'him', 'terribly', '.', '\\n\\n', 'xxmaj', 'during', 'the', 'day', 'a', 'mild', '-', 'manner', 'accountant', ',', 'and', 'at', 'night', 'he', 'breaks', 'into', 'cemeteries', 'and', 'funeral', 'homes', 'and', 'drinks', 'the', 'blood', 'of', 'dead', 'girls', '.', 'xxmaj', 'they', 'are', 'all', 'attractive', ',', 'of', 'course', ',', 'else', 'we', 'would', \"n't\", 'care', 'about', 'the', 'fact', 'that', 'he', 'usually', 'tears', 'their', 'clothing', 'down', 'to', 'the', 'waist', '.', 'xxmaj', 'he', 'graduates', 'eventually', 'to', 'actually', 'killing', ',', 'and', 'that', 'is', 'what', 'gets', 'him', 'caught', '.', '\\n\\n', 'xxmaj', 'like', 'i', 'said', ',', 'a', 'very', 'strange', 'movie', 'that', 'is', 'dark', 'and', 'very', 'slow', 'as', 'xxmaj', 'werner', 'xxmaj', 'pochath', 'never', 'talks', 'and', 'just', 'spends', 'his', 'time', 'drinking', 'blood', '.'],['xxbos', 'xxmaj', 'being', 'a', 'long', '-', 'time', 'fan', 'of', 'xxmaj', 'japanese', 'film', ',', 'i', 'expected', 'more', 'than', 'this', '.', 'i', 'ca', \"n't\", 'really', 'be', 'bothered', 'to', 'write', 'to', 'much', ',', 'as', 'this', 'movie', 'is', 'just', 'so', 'poor', '.', 'xxmaj', 'the', 'story', 'might', 'be', 'the', 'cutest', 'romantic', 'little', 'something', 'ever', ',', 'pity', 'i', 'could', \"n't\", 'stand', 'the', 'awful', 'acting', ',', 'the', 'mess', 'they', 'called', 'pacing', ',', 'and', 'the', 'standard', '\"', 'quirky', '\"', 'xxmaj', 'japanese', 'story', '.', 'xxmaj', 'if', 'you', \"'ve\", 'noticed', 'how', 'many', 'xxmaj', 'japanese', 'movies', 'use', 'characters', ',', 'plots', 'and', 'twists', 'that', 'seem', 'too', '\"', 'different', '\"', ',', 'forcedly', 'so', ',', 'then', 'steer', 'clear', 'of', 'this', 'movie', '.', 'xxmaj', 'seriously', ',', 'a', '12', '-', 'year', 'old', 'could', 'have', 'told', 'you', 'how', 'this', 'movie', 'was', 'going', 'to', 'move', 'along', ',', 'and', 'that', \"'s\", 'not', 'a', 'good', 'thing', 'in', 'my', 'book', '.', '\\n\\n', 'xxmaj', 'fans', 'of', '\"', 'beat', '\"', 'xxmaj', 'takeshi', ':', 'his', 'part', 'in', 'this', 'movie', 'is', 'not', 'really', 'more', 'than', 'a', 'cameo', ',', 'and', 'unless', 'you', \"'re\", 'a', 'rabid', 'fan', ',', 'you', 'do', \"n't\", 'need', 'to', 'suffer', 'through', 'this', 'waste', 'of', 'film', '.', '\\n\\n', '2', '/', '10'],['xxbos', '\"', 'tokyo', 'xxmaj', 'eyes', '\"', 'tells', 'of', 'a', '17', 'year', 'old', 'xxmaj', 'japanese', 'girl', 'who', 'falls', 'in', 'like', 'with', 'a', 'man', 'being', 'hunted', 'by', 'her', 'big', 'bro', 'who', 'is', 'a', 'cop', '.', 'xxmaj', 'this', 'lame', 'flick', 'is', 'about', '50', '%', 'filler', 'and', '50', '%', 'talk', ',', 'talk', ',', 'and', 'more', 'talk', '.', 'xxmaj', 'you', \"'ll\", 'get', 'to', 'see', 'the', 'less', 'than', 'stellar', 'cast', 'of', 'three', 'as', 'they', 'talk', 'on', 'the', 'bus', ',', 'talk', 'and', 'play', 'video', 'games', ',', 'talk', 'and', 'get', 'a', 'haircut', ',', 'talk', 'and', 'walk', 'and', 'walk', 'and', 'talk', ',', 'talk', 'on', 'cell', 'phones', ',', 'hang', 'out', 'and', 'talk', ',', 'etc', '.', 'as', 'you', 'read', 'subtitles', 'waiting', 'for', 'something', 'to', 'happen', '.', 'xxmaj', 'the', 'thin', 'wisp', 'of', 'a', 'story', 'is', 'not', 'sufficient', 'to', 'support', 'a', 'film', 'with', 'low', 'end', 'production', 'value', ',', 'a', 'meager', 'cast', ',', 'and', 'no', 'action', ',', 'no', 'romance', ',', 'no', 'sex', 'or', 'nudity', ',', 'no', 'heavy', 'drama', '…', 'just', 'incessant', \"yadayadayada'ing\", '.', '(', 'c-', ')'],['xxbos', 'xxmaj', 'wealthy', 'horse', 'ranchers', 'in', 'xxmaj', 'buenos', 'xxmaj', 'aires', 'have', 'a', 'long', '-', 'standing', 'no', '-', 'trading', 'policy', 'with', 'the', 'xxmaj', 'crawfords', 'of', 'xxmaj', 'manhattan', ',', 'but', 'what', 'happens', 'when', 'the', 'mustachioed', 'xxmaj', 'latin', 'son', 'falls', 'for', 'a', 'certain', 'xxmaj', 'crawford', 'with', 'bright', 'eyes', ',', 'blonde', 'hair', ',', 'and', 'some', 'perky', 'moves', 'on', 'the', 'dance', 'floor', '?', '20th', 'century', '-', 'fox', 'musical', 'has', 'a', 'glossy', 'veneer', 'yet', 'seems', 'a', 'bit', 'tatty', 'around', 'the', 'edges', '.', 'xxmaj', 'it', 'is', 'very', 'heavy', 'on', 'the', 'frenetic', ',', 'gymnastic', '-', 'like', 'dancing', ',', 'exceedingly', 'thin', 'on', 'story', '.', 'xxmaj', 'betty', 'xxmaj', 'grable', '(', 'an', 'eleventh', 'hour', 'replacement', 'for', 'xxmaj', 'alice', 'xxmaj', 'faye', ')', 'gives', 'it', 'a', 'boost', ',', 'even', 'though', 'she', \"'s\", 'paired', 'with', 'leaden', 'xxmaj', 'don', 'xxmaj', 'ameche', '(', 'in', 'tan', 'make', '-', 'up', 'and', 'slick', 'hair', ')', '.', 'xxmaj', 'also', 'good', ':', 'xxmaj', 'charlotte', 'xxmaj', 'greenwood', 'as', 'xxmaj', 'betty', \"'s\", 'pithy', 'aunt', ',', 'a', 'limousine', 'driver', 'who', \"'s\", 'constantly', 'asleep', 'on', 'the', 'job', ',', 'and', 'xxmaj', 'carmen', 'xxmaj', 'miranda', 'playing', 'herself', '(', 'who', 'else', '?', ')', '.', 'xxmaj', 'the', 'stock', 'shots', 'of', 'xxmaj', 'argentina', 'far', 'outclass', 'the', 'action', 'filmed', 'on', 'the', 'xxmaj', 'fox', 'backlot', ',', 'and', 'some', 'of', 'the', 'supporting', 'performances', 'are', 'quite', 'awful', '.', 'xxmaj', 'by', 'the', 'time', 'of', 'the', 'big', 'horserace', 'finale', ',', 'most', 'viewers', 'will', 'have', 'had', 'enough', '.', '*', '1', '/', '2', 'from', 'xxrep', '4', '*']...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于Numericalize的setup函数：\n",
    "在代码中是这样计数的：\n",
    "```Python\n",
    "count = dsets.counter if getattr(dsets, 'counter', None) is not None else Counter(p for o in dsets for p in o)\n",
    "```\n",
    "Counter中传入的要求是一个二维数组/数组内还有数组，如果传入的是`toks200[0]`的话counter中的dsets是列表，o是单词，p是每个字符abcd...，所以输出的结果中全是单字母形式；如果传入的是`toks200`，那么counter中的dsets是二维列表，o就是每个`toks200[i]`列表，p才是单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#1968) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the','.',',','a','and','of','to','is','it','i','in'...]\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "coll_repr(num.vocab,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,  349,  183,    8, 1177,   10,    8, 1178,   60, 1455,   62,   12,   25,   28,  189,  957,   93,  958,   10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = num(toks)[:20]; nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj once again xxmaj mr . xxmaj costner has dragged out a movie for far longer than necessary .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Our Texts into Batches for a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>chapter</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>classifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>chapter</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>xxup</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>for</td>\n",
       "      <td>a</td>\n",
       "      <td>while</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
    "tokens = tkn(stream)\n",
    "bs,seq_len = 6,15\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,seq_len = 6,5\n",
    "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chapter</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>xxup</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,seq_len = 6,5\n",
    "d_tokens = np.array([tokens[i*15+seq_len:i*15+2*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>classifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it</td>\n",
       "      <td>for</td>\n",
       "      <td>a</td>\n",
       "      <td>while</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,seq_len = 6,5\n",
    "d_tokens = np.array([tokens[i*15+10:i*15+15] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums200 = toks200.map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 207)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums200),len(nums200[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56228\n"
     ]
    }
   ],
   "source": [
    "total_lens=0\n",
    "for i in nums200:\n",
    "    total_lens+=len(i)\n",
    "print(total_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59904"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*64*72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = first(dl)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj once again xxmaj mr . xxmaj costner has dragged out a movie for far longer than necessary .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in x[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj once again xxmaj mr . xxmaj costner has dragged out a movie for far longer than necessary . xxmaj'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in y[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Using DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
    "\n",
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
    ").dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj africa xxmaj screams , one of the least seen of abbott&amp;costello 's films was an independent production that was released through xxmaj united xxmaj artists . xxmaj the thin plot has xxmaj hillary xxmaj brooke believing xxmaj costello has the map to a hidden territory that is rich with diamonds . xxmaj bud and xxmaj lou go to xxmaj africa at her behest with her two companions , the fighting xxmaj baer xxmaj brothers . xxmaj of course</td>\n",
       "      <td>xxmaj africa xxmaj screams , one of the least seen of abbott&amp;costello 's films was an independent production that was released through xxmaj united xxmaj artists . xxmaj the thin plot has xxmaj hillary xxmaj brooke believing xxmaj costello has the map to a hidden territory that is rich with diamonds . xxmaj bud and xxmaj lou go to xxmaj africa at her behest with her two companions , the fighting xxmaj baer xxmaj brothers . xxmaj of course the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj xxunk and they got the balls to make the xxmaj christians out to be the intolerant , xenophobic and reactionary half - wits . \\n\\n xxmaj moral xxmaj orel is still an interesting watch ( as long as it comes between superior shows on xxmaj adult xxmaj swim ) because it is a satire . xxmaj however , xxmaj it is more a satire on the people that make it rather then the people it is depicting . \\n\\n</td>\n",
       "      <td>xxunk and they got the balls to make the xxmaj christians out to be the intolerant , xenophobic and reactionary half - wits . \\n\\n xxmaj moral xxmaj orel is still an interesting watch ( as long as it comes between superior shows on xxmaj adult xxmaj swim ) because it is a satire . xxmaj however , xxmaj it is more a satire on the people that make it rather then the people it is depicting . \\n\\n xxmaj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 09:19&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='198' class='' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      7.53% [198/2630 27:58&lt;5:43:41 4.3872]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
    "         for _ in range(N_SENTENCES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Classifier DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastai.data.transforms.parent_label(o)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas = DataBlock(\n",
    "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab),CategoryBlock),\n",
    "    get_y = parent_label,\n",
    "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ").dataloaders(path, path=path, bs=128, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_samp = toks200[:10].map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_samp.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disinformation and Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is \"self-supervised learning\"?\n",
    "1. What is a \"language model\"?\n",
    "1. Why is a language model considered self-supervised?\n",
    "1. What are self-supervised models usually used for?\n",
    "1. Why do we fine-tune language models?\n",
    "1. What are the three steps to create a state-of-the-art text classifier?\n",
    "1. How do the 50,000 unlabeled movie reviews help us create a better text classifier for the IMDb dataset?\n",
    "1. What are the three steps to prepare your data for a language model?\n",
    "1. What is \"tokenization\"? Why do we need it?\n",
    "1. Name three different approaches to tokenization.\n",
    "1. What is `xxbos`?\n",
    "1. List four rules that fastai applies to text during tokenization.\n",
    "1. Why are repeated characters replaced with a token showing the number of repetitions and the character that's repeated?\n",
    "1. What is \"numericalization\"?\n",
    "1. Why might there be words that are replaced with the \"unknown word\" token?\n",
    "1. With a batch size of 64, the first row of the tensor representing the first batch contains the first 64 tokens for the dataset. What does the second row of that tensor contain? What does the first row of the second batch contain? (Careful—students often get this one wrong! Be sure to check your answer on the book's website.)\n",
    "1. Why do we need padding for text classification? Why don't we need it for language modeling?\n",
    "1. What does an embedding matrix for NLP contain? What is its shape?\n",
    "1. What is \"perplexity\"?\n",
    "1. Why do we have to pass the vocabulary of the language model to the classifier data block?\n",
    "1. What is \"gradual unfreezing\"?\n",
    "1. Why is text generation always likely to be ahead of automatic identification of machine-generated texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. See what you can learn about language models and disinformation. What are the best language models today? Take a look at some of their outputs. Do you find them convincing? How could a bad actor best use such a model to create conflict and uncertainty?\n",
    "1. Given the limitation that models are unlikely to be able to consistently recognize machine-generated texts, what other approaches may be needed to handle large-scale disinformation campaigns that leverage deep learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
